{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bgi3VJQgpuvv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bgi3VJQgpuvv",
    "outputId": "37178cc5-b516-4142-a4e8-aa0682205074"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa1b9f",
   "metadata": {
    "id": "62aa1b9f"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomRotation\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomZoom\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e005f758",
   "metadata": {
    "id": "e005f758"
   },
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "tf.random.set_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b50f0c",
   "metadata": {
    "id": "a8b50f0c"
   },
   "source": [
    "## Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uAcaFDlzsCos",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uAcaFDlzsCos",
    "outputId": "0b63e3d2-f1bf-4fdb-e300-789bfb540ac5"
   },
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b1711",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "914b1711",
    "outputId": "702f19da-c3c0-4492-b11b-40c9c7d26087"
   },
   "outputs": [],
   "source": [
    "# Directory\n",
    "dir_cur = os.getcwd()\n",
    "print(dir_cur)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rt12m-iArOVD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rt12m-iArOVD",
    "outputId": "c8cedd34-4464-4745-ae12-0c90d138826c"
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mMyCx16ooyOc",
   "metadata": {
    "id": "mMyCx16ooyOc"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/plants_recognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a91cfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "86a91cfe",
    "outputId": "b9a61a1e-6884-4a6c-b9dd-6818208b515a"
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155741db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "155741db",
    "outputId": "231ec976-89e0-49ec-b507-b268e4553c8f"
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee550fd",
   "metadata": {
    "id": "bee550fd"
   },
   "outputs": [],
   "source": [
    "# Path to training data\n",
    "path_training_data = Path(\"fruits/Training\")\n",
    "\n",
    "# Path to test data\n",
    "path_test_data = Path(\"fruits/Test\")\n",
    "\n",
    "# Listing folder contents\n",
    "training_img = list(path_training_data.glob(\"*/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1d0c7",
   "metadata": {
    "id": "7bd1d0c7"
   },
   "outputs": [],
   "source": [
    "# Lambda expression that extracts only the value with the path of each image\n",
    "training_img = list(map(lambda x: str(x), training_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-zPcUYJY72Qk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-zPcUYJY72Qk",
    "outputId": "1b07c697-7553-4cc3-fe49-39fd11619d22"
   },
   "outputs": [],
   "source": [
    "# View a sample list\n",
    "training_img[725:736]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade6360",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ade6360",
    "outputId": "554eb9e3-8df2-4930-ca67-7aa6547b929e"
   },
   "outputs": [],
   "source": [
    "# Total training images\n",
    "len(training_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc217600",
   "metadata": {
    "id": "dc217600"
   },
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ffe83b",
   "metadata": {
    "id": "21ffe83b"
   },
   "outputs": [],
   "source": [
    "# Function that gets the label of each image\n",
    "def get_label(path_img):\n",
    "    return path_img.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704f711",
   "metadata": {
    "id": "f704f711"
   },
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "img_training_labels = list(map(lambda x: get_label(x), training_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a61d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "320a61d1",
    "outputId": "0e8c5e5a-e6c8-4053-bb0a-ab2eea36e9ea"
   },
   "outputs": [],
   "source": [
    "# Visualizing sample\n",
    "img_training_labels[740:751]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d57e2c",
   "metadata": {
    "id": "14d57e2c"
   },
   "outputs": [],
   "source": [
    "# Create the object\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac5ee9",
   "metadata": {
    "id": "cfac5ee9"
   },
   "outputs": [],
   "source": [
    "# Apply the fit_transform\n",
    "img_training_labels = encoder.fit_transform(img_training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d323d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "514d323d",
    "outputId": "71b843ef-5e4f-4cc6-c4a6-33a4c71f9dc4"
   },
   "outputs": [],
   "source": [
    "# Visualizing sample\n",
    "img_training_labels[740:745]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37f272",
   "metadata": {
    "id": "4b37f272"
   },
   "outputs": [],
   "source": [
    "# Apply One-Hot-Encoding on the labels\n",
    "img_training_labels = tf.keras.utils.to_categorical(img_training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db2a34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54db2a34",
    "outputId": "62728349-3f28-4146-af79-3ad0aa80f511"
   },
   "outputs": [],
   "source": [
    "# Visualizing sample\n",
    "img_training_labels[740:745]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77d312",
   "metadata": {
    "id": "1e77d312"
   },
   "outputs": [],
   "source": [
    "# Split the training data into two samples, training and validation\n",
    "X_traning, X_valid, Y_traning, Y_valid = train_test_split(training_img, img_training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a90df9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6a90df9",
    "outputId": "06e532ad-8dc9-4fda-aa8a-de46f9225e41"
   },
   "outputs": [],
   "source": [
    "print(\"X Training\\n\", X_traning[10:13])\n",
    "print(\"Y Training\\n\",Y_traning[10:13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ab992",
   "metadata": {
    "id": "f58ab992"
   },
   "source": [
    "## Dataset Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffab855",
   "metadata": {
    "id": "5ffab855"
   },
   "outputs": [],
   "source": [
    "# Resizing all images to 224 x 224\n",
    "img_size = 224\n",
    "resize = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.Resizing(img_size, img_size)])\n",
    "\n",
    "# Create object for augmentation dataset\n",
    "data_augmentation = tf.keras.Sequential([RandomFlip(\"horizontal\"),\n",
    "                                         RandomRotation(0.2),\n",
    "                                         RandomZoom(height_factor = (-0.3,-0.2)) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0679bb",
   "metadata": {
    "id": "bd0679bb"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a290c0a",
   "metadata": {
    "id": "0a290c0a"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "autotune = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb1b73",
   "metadata": {
    "id": "01eb1b73"
   },
   "outputs": [],
   "source": [
    "# Function to load and transform images\n",
    "def loading_transform(image, label):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image, channels = 3)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94df3c4",
   "metadata": {
    "id": "f94df3c4"
   },
   "outputs": [],
   "source": [
    "# Function to prepare data in TensorFlow format\n",
    "def prepare_dataset(path, labels, train = True):\n",
    "\n",
    "    # Prepare the data\n",
    "    image_paths = tf.convert_to_tensor(path)\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "    dataset = dataset.map(lambda image, label: loading_transform(image, label)) \n",
    "    dataset = dataset.map(lambda image, label: (resize(image), label), num_parallel_calls = autotune)\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    if train:\n",
    "        dataset = dataset.map(lambda image, label: (data_augmentation(image), label), num_parallel_calls = autotune)\n",
    "  \n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df664be",
   "metadata": {
    "id": "6df664be"
   },
   "outputs": [],
   "source": [
    "# Create the training dataset\n",
    "dataset_training = prepare_dataset(X_traning, Y_traning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2690df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a2690df",
    "outputId": "823e2fa1-d9af-438e-c76e-82fc0c0a5ea4"
   },
   "outputs": [],
   "source": [
    "# Shape\n",
    "img, label = next(iter(dataset_training))\n",
    "print(img.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6791a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "19f6791a",
    "outputId": "f52a0fa1-5882-4f69-e149-e0a4214142a7"
   },
   "outputs": [],
   "source": [
    "# Visualize an image and a label\n",
    "print(encoder.inverse_transform(np.argmax(label, axis = 1))[0])\n",
    "plt.imshow((img[0].numpy()/255).reshape(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4cf96",
   "metadata": {
    "id": "7cd4cf96"
   },
   "outputs": [],
   "source": [
    "# Create the validation dataset\n",
    "dataset_valid = prepare_dataset(X_valid, Y_valid, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209cf82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2209cf82",
    "outputId": "1c0f7708-24e2-47e4-ae48-a4c607301bd9"
   },
   "outputs": [],
   "source": [
    "# Shape\n",
    "img, label = next(iter(dataset_valid))\n",
    "print(img.shape) \n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3a8d6b",
   "metadata": {
    "id": "cc3a8d6b"
   },
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd0b17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5cd0b17",
    "outputId": "d55e478f-272d-4eef-c644-87f2d8437599"
   },
   "outputs": [],
   "source": [
    "# Loading a pre-trained model\n",
    "model_pre = EfficientNetB3(input_shape = (224,224,3), include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aaa5cd",
   "metadata": {
    "id": "b8aaa5cd"
   },
   "outputs": [],
   "source": [
    "# Adding our own layers to model_pre\n",
    "model = tf.keras.Sequential([model_pre,\n",
    "                              tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                              tf.keras.layers.Dense(131, activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c504fa0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c504fa0",
    "outputId": "1ef018a7-e4c2-4f08-9743-96ddedbba7b8"
   },
   "outputs": [],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8c4aa",
   "metadata": {
    "id": "90f8c4aa"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 0.001\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "ep = 1e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcee026",
   "metadata": {
    "id": "4fcee026"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer = Adam(learning_rate = lr, \n",
    "                                beta_1 = beta1, \n",
    "                                beta_2 = beta2, \n",
    "                                epsilon = ep),\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy', Precision(name = 'precision'), Recall(name = 'recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a43be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c47a43be",
    "outputId": "4f590acc-6c93-46de-ce0f-b379a126b8c1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(dataset_training,\n",
    "                     steps_per_epoch = len(X_traning)//batch_size,\n",
    "                     epochs = 1,\n",
    "                     validation_data = dataset_valid,\n",
    "                     validation_steps = len(Y_traning)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8fb35",
   "metadata": {
    "id": "b5c8fb35"
   },
   "outputs": [],
   "source": [
    "# Don't need the model_pre anymore\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103fc521",
   "metadata": {
    "id": "103fc521"
   },
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "bestModel = tf.keras.callbacks.ModelCheckpoint(\"model/best_model.h5\", \n",
    "                                                verbose = 1, \n",
    "                                                save_best = True, \n",
    "                                                save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110733e",
   "metadata": {
    "id": "2110733e"
   },
   "outputs": [],
   "source": [
    "# Early stop\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience = 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc113dd",
   "metadata": {
    "id": "cdc113dd"
   },
   "outputs": [],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30700994",
   "metadata": {
    "id": "30700994"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(dataset_training,\n",
    "                     steps_per_epoch = len(X_traning)//batch_size,\n",
    "                     epochs = 6,\n",
    "                     validation_data = dataset_valid,\n",
    "                     validation_steps = len(Y_traning)//batch_size,\n",
    "                     callbacks = [bestModel, early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZEzMQ4Tqbqtd",
   "metadata": {
    "id": "ZEzMQ4Tqbqtd"
   },
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tAUbNzqwb4KU",
   "metadata": {
    "id": "tAUbNzqwb4KU"
   },
   "outputs": [],
   "source": [
    "# To load the weights we need to unfreeze the layers\n",
    "model.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kwFovVrQYFrY",
   "metadata": {
    "id": "kwFovVrQYFrY"
   },
   "outputs": [],
   "source": [
    "# Load checkpoint weights and re-evaluate\n",
    "model.load_weights(\"model/best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XMw3yU9CYFx0",
   "metadata": {
    "id": "XMw3yU9CYFx0"
   },
   "outputs": [],
   "source": [
    "# Loading and preparing test data\n",
    "path_img_test = list(path_test_data.glob(\"*/*\"))\n",
    "test_img = list(map(lambda x: str(x), path_img_test))\n",
    "img_test_labels = list(map(lambda x: get_label(x), test_img))\n",
    "img_test_labels = encoder.fit_transform(img_test_labels)\n",
    "img_test_labels = tf.keras.utils.to_categorical(img_test_labels)\n",
    "test_image_paths = tf.convert_to_tensor(test_img)\n",
    "img_test_labels = tf.convert_to_tensor(img_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ug9-AsXbdCOJ",
   "metadata": {
    "id": "ug9-AsXbdCOJ"
   },
   "outputs": [],
   "source": [
    "# Image decode function\n",
    "def decode_img(image, label):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image, channels = 3)\n",
    "    image = tf.image.resize(image, [224,224], method = \"bilinear\")\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IxNYuQWZhV1e",
   "metadata": {
    "id": "IxNYuQWZhV1e"
   },
   "outputs": [],
   "source": [
    "# Create the test dataset\n",
    "dataset_test = (tf.data.Dataset\n",
    "                 .from_tensor_slices((test_img, img_test_labels))\n",
    "                 .map(decode_img)\n",
    "                 .batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7K8e890-hgFA",
   "metadata": {
    "id": "7K8e890-hgFA"
   },
   "outputs": [],
   "source": [
    "# Shape\n",
    "img, label = next(iter(dataset_test))\n",
    "print(img.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VBrpD1EXhoE0",
   "metadata": {
    "id": "VBrpD1EXhoE0"
   },
   "outputs": [],
   "source": [
    "# Visualizing a test image\n",
    "print(encoder.inverse_transform(np.argmax(label, axis = 1))[0])\n",
    "plt.imshow((img[0].numpy()/255).reshape(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W8EZSW8jhsbF",
   "metadata": {
    "id": "W8EZSW8jhsbF"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "loss, acc, prec, rec = model.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5sySltyahv9H",
   "metadata": {
    "id": "5sySltyahv9H"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", acc)\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EQxZZDuriD56",
   "metadata": {
    "id": "EQxZZDuriD56"
   },
   "source": [
    "## Trained Model Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lGYd53etiRJs",
   "metadata": {
    "id": "lGYd53etiRJs"
   },
   "outputs": [],
   "source": [
    "# Function to load a new image\n",
    "def loading_new_img(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.io.decode_jpeg(img, channels = 3)\n",
    "    img = tf.image.resize(img, [224,224], method = \"bilinear\")\n",
    "    plt.imshow(img.numpy()/255)\n",
    "    img = tf.expand_dims(img, 0) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Px1O5a-7hx_W",
   "metadata": {
    "id": "Px1O5a-7hx_W"
   },
   "outputs": [],
   "source": [
    "# Function to make predictions\n",
    "def predition_func(img_path, model, enc):\n",
    "    img = loading_new_img(img_path)\n",
    "    prediction = model.predict(img)\n",
    "    pred = np.argmax(prediction, axis = 1) \n",
    "    return enc.inverse_transform(pred)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FN5t7x6VkSvd",
   "metadata": {
    "id": "FN5t7x6VkSvd"
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predition_func(\"images/image1.jpg\", model, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GSPfstgskS7w",
   "metadata": {
    "id": "GSPfstgskS7w"
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predition_func(\"images/image2.jpg\", model, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p4xtxi5okrvN",
   "metadata": {
    "id": "p4xtxi5okrvN"
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predition_func(\"images/image3.jpg\", model, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m6BsmX8TksN4",
   "metadata": {
    "id": "m6BsmX8TksN4"
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predition_func(\"images/image4.jpg\", model, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SZh6qfNYk1nt",
   "metadata": {
    "id": "SZh6qfNYk1nt"
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "predition_func(\"images/image5.jpg\", model, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lPTSUSP9ut5w",
   "metadata": {
    "id": "lPTSUSP9ut5w"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Plant_Recognition_Project_testing_22_07_28.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
